{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "import random \n",
    "import pandas as pd \n",
    "import glob \n",
    "from pydub import AudioSegment\n",
    "from pydub.generators import WhiteNoise\n",
    "sys.path.append('/root')\n",
    "from nas_tools.utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载数据\n",
    "1. tts数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已下载并保存为: /root/nuna_simulation_test/data/tts_data/complete_tts_table.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file(\n",
    "    remote_filepath='boweihan/data/synthesis_data/tts_data/complete_tts_table.csv'\n",
    "    ,local_filepath='/root/nuna_simulation_test/data/tts_data/complete_tts_table.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tts_model</th>\n",
       "      <th>voice_id</th>\n",
       "      <th>model_voice_id</th>\n",
       "      <th>style</th>\n",
       "      <th>emotion_value</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>conversation_index</th>\n",
       "      <th>voice_nas_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>murf</td>\n",
       "      <td>voicee042859e-168d-47cc-ac6e-7a6cb29f5ed5</td>\n",
       "      <td>en-US-cooper</td>\n",
       "      <td>Disappointment</td>\n",
       "      <td>Disappointment</td>\n",
       "      <td>11</td>\n",
       "      <td>dfd62aaa-1cae-40ba-aca8-f237fefcac71</td>\n",
       "      <td>0</td>\n",
       "      <td>boweihan/data/synthesis_data/tts_data/murf_tts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>murf</td>\n",
       "      <td>voice18e00ace-fcd1-462b-949e-c3f857996ae8</td>\n",
       "      <td>en-US-charles</td>\n",
       "      <td>Sobbing</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>6</td>\n",
       "      <td>dfd62aaa-1cae-40ba-aca8-f237fefcac71</td>\n",
       "      <td>1</td>\n",
       "      <td>boweihan/data/synthesis_data/tts_data/murf_tts...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tts_model                                   voice_id model_voice_id  \\\n",
       "0      murf  voicee042859e-168d-47cc-ac6e-7a6cb29f5ed5   en-US-cooper   \n",
       "1      murf  voice18e00ace-fcd1-462b-949e-c3f857996ae8  en-US-charles   \n",
       "\n",
       "            style   emotion_value  emotion_id  \\\n",
       "0  Disappointment  Disappointment          11   \n",
       "1         Sobbing         Sadness           6   \n",
       "\n",
       "                        conversation_id  conversation_index  \\\n",
       "0  dfd62aaa-1cae-40ba-aca8-f237fefcac71                   0   \n",
       "1  dfd62aaa-1cae-40ba-aca8-f237fefcac71                   1   \n",
       "\n",
       "                                      voice_nas_path  \n",
       "0  boweihan/data/synthesis_data/tts_data/murf_tts...  \n",
       "1  boweihan/data/synthesis_data/tts_data/murf_tts...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tts_data = pd.read_csv('/root/nuna_simulation_test/data/tts_data/complete_tts_table.csv') \n",
    "all_tts_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6263\n"
     ]
    }
   ],
   "source": [
    "all_conversation_id_list = list(set(all_tts_data['conversation_id'].values.tolist()))\n",
    "print(len(all_conversation_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e8276765-7cc3-4351-b8b2-c015e72a1e80',\n",
       " 'f885db12-4d1f-4df3-9284-ec9306614824',\n",
       " '45d03483-dc2f-4a14-b23f-1f4f39c9fb3f',\n",
       " 'c0b80c67-3324-42af-99b6-2c9870c75205',\n",
       " '1d0b3361-f2bc-45df-9472-6fa278faee36']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_conversation_list = random.sample(all_conversation_id_list, 5)\n",
    "sampled_conversation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'Pleasure（Happy)', 10: 'Frustration', 4: 'Admiration'}\n"
     ]
    }
   ],
   "source": [
    "tts_data_dict = {} \n",
    "tts_local_folder_path = '/root/nuna_simulation_test/data/tts_data/conversation_turn_data/'\n",
    "for conv_id in sampled_conversation_list:\n",
    "    temp_data = all_tts_data[all_tts_data['conversation_id'] == conv_id] \n",
    "    conversation_index_list = temp_data['conversation_index'].values.tolist() \n",
    "    emotion_value_list = temp_data['emotion_value'].values.tolist()  \n",
    "    emotion_id_list = temp_data['emotion_id'].values.tolist() \n",
    "    voice_nas_path_list = temp_data['voice_nas_path'].values.tolist() \n",
    "    user_all_emotion_dict = {}\n",
    "    assistant_all_emotion_dict = {}\n",
    "    for i in range(len(temp_data)): \n",
    "        conversation_index = conversation_index_list[i] \n",
    "        emotion_value = emotion_value_list[i] \n",
    "        emotion_id = emotion_id_list[i] \n",
    "        voice_nas_path = voice_nas_path_list[i]\n",
    "        local_filepath = os.path.join(tts_local_folder_path, conv_id, voice_nas_path.split('/')[-1]) \n",
    "        # download_file(\n",
    "        #     remote_filepath=voice_nas_path\n",
    "        #     ,local_filepath=local_filepath\n",
    "        # )\n",
    "        if conv_id not in tts_data_dict:\n",
    "            tts_data_dict[conv_id] = {}\n",
    "        tts_data_dict[conv_id][conversation_index] = {\n",
    "            'conv_id': conv_id \n",
    "            ,'emotion_value': emotion_value \n",
    "            ,'emotion_id': emotion_id \n",
    "            ,'voice_nas_path': voice_nas_path \n",
    "            ,'conversation_index': conversation_index \n",
    "            ,'local_filepath': local_filepath\n",
    "        }\n",
    "        if int(conversation_index) % 2 != 0:\n",
    "            user_all_emotion_dict[emotion_id] = emotion_value \n",
    "        else: \n",
    "            assistant_all_emotion_dict[emotion_id] = emotion_value\n",
    "    print(all_emotion_dict)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/tts_data.json\", \"w\", encoding=\"utf-8\") as write_f:\n",
    "    json.dump(tts_data_dict, write_f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已下载并保存为: /root/nuna_simulation_test/data/noise_data/audio_scene_label.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file(\n",
    "    remote_filepath='chaoqun/audio_scene_label.csv'\n",
    "    ,local_filepath=os.path.join(f'/root/nuna_simulation_test/data/noise_data/audio_scene_label.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_name</th>\n",
       "      <th>first_scene</th>\n",
       "      <th>second_scene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATMs_1_001.wav</td>\n",
       "      <td>Banks and Financial Institutions</td>\n",
       "      <td>ATMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATMs_1_002.wav</td>\n",
       "      <td>Banks and Financial Institutions</td>\n",
       "      <td>ATMs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       audio_name                       first_scene second_scene\n",
       "0  ATMs_1_001.wav  Banks and Financial Institutions         ATMs\n",
       "1  ATMs_1_002.wav  Banks and Financial Institutions         ATMs"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_scene_data = pd.read_csv('/root/nuna_simulation_test/data/noise_data/audio_scene_label.csv')\n",
    "audio_scene_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载所有噪音切片数据，如果已下载则注释\n",
    "# second_scene_list = list(set(audio_scene_data['second_scene'].values.tolist()))\n",
    "# print(second_scene_list)\n",
    "# for second_scene in second_scene_list: \n",
    "#     temp_data = audio_scene_data[audio_scene_data['second_scene'] == second_scene].sample(10) \n",
    "#     audio_name_list = temp_data['audio_name'].values.tolist() \n",
    "#     first_scene_list11 = temp_data['first_scene'].values.tolist()\n",
    "#     second_scene_list11 = temp_data['second_scene'].values.tolist()\n",
    "#     print(len(temp_data))\n",
    "#     # break/ \n",
    "#     for i in range(len(temp_data)):\n",
    "#         nas_file_path = os.path.join('chaoqun/scene_audio_from_youtube', first_scene_list11[i], second_scene_list11[i], audio_name_list[i]) \n",
    "#         print(nas_file_path)\n",
    "#         download_file(\n",
    "#             remote_filepath=nas_file_path\n",
    "#             ,local_filepath=os.path.join(f'/root/nuna_simulation_test/data/noise_data/second_scene/{second_scene_list11[i]}/{audio_name_list[i]}')\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make origin voice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_datapath = './data/noise_data/second_scene/' \n",
    "tts_datapath = './data/tts_data/conversation_turn_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fitness studios', 'Bedroom', 'Churches', 'synagogues', 'clinics', 'kitchen', 'Post offices', 'Supermarkets', 'trails', 'town halls', 'Gas stations', 'train stations', 'Gyms', 'Bus stops', 'Restaurants', 'Banks', 'Public libraries', 'university libraries', 'mosques', 'university', 'factory', 'malls', 'Rec centers', 'School', 'living room', 'Parks', 'coffee shops', 'Office', 'ATMs', 'Hospitals']\n",
      "['7aae8ae6-efed-4e26-8a94-3233dea7cc21', 'e9f6bbeb-5742-4efd-a80b-4798c9109b33', 'cc722536-b171-4118-80c8-9960974c043c', 'ef8a5858-8416-40c2-91e7-480da1934834', '9dd6082d-2058-4158-9bbe-0f8d209f4910']\n"
     ]
    }
   ],
   "source": [
    "def get_all_folders_from_path(folder_path):\n",
    "    # 获取所有文件和文件夹名称\n",
    "    all_items = os.listdir(folder_path)\n",
    "    # 筛选出文件夹\n",
    "    return [item for item in all_items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "\n",
    "all_scene_noise_folder_list = get_all_folders_from_path(noise_datapath)\n",
    "print(all_scene_noise_folder_list)\n",
    "\n",
    "all_tts_folder_list = get_all_folders_from_path(tts_datapath)\n",
    "print(all_tts_folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/noise_data/second_scene/Office/Office_1_127.wav'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_wav_files_from_folder_path(folder_path): \n",
    "    rst1 = glob.glob(f\"{folder_path}/*.wav\")\n",
    "    rst2 = glob.glob(f\"{folder_path}/*.WAV\")\n",
    "    return rst1 + rst2\n",
    "\n",
    "def get_random_noise_voice_data(folder_path): \n",
    "    noise_folder_path = random.choice(all_scene_noise_folder_list) \n",
    "    all_scene_wav_files = get_all_wav_files_from_folder_path(os.path.join(folder_path, noise_folder_path)) \n",
    "    return random.choice(all_scene_wav_files)\n",
    "\n",
    "get_random_noise_voice_data(noise_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tts_human_voice_data(folder_path, output_file, min_pause=1000, max_pause=5000): \n",
    "    tts_folder_path = random.choice(all_tts_folder_list) \n",
    "    all_conversation_turn_files = get_all_wav_files_from_folder_path(os.path.join(folder_path, tts_folder_path)) \n",
    "    all_conversation_turn_file_dict = {}\n",
    "    for filename in all_conversation_turn_files:\n",
    "        wav_name = filename.split('/')[-1] \n",
    "        turn_cnt = int(wav_name.split('_')[-1].replace('.wav', '').replace('.WAV', '')) \n",
    "        all_conversation_turn_file_dict[turn_cnt] = filename\n",
    "    sorted_all_conversation_turn_file_dict = dict(sorted(all_conversation_turn_file_dict.items(), key=lambda item: item[0], reverse=False))\n",
    "    # print(sorted_all_conversation_turn_file_dict) \n",
    "    combined = AudioSegment.silent(duration=0) # 初始化空白音频段\n",
    "    cnt = 0 \n",
    "    for _, turn_audio_datapath in sorted_all_conversation_turn_file_dict.items(): \n",
    "        # print(turn_audio_datapath)\n",
    "        segment = AudioSegment.from_wav(turn_audio_datapath) \n",
    "        combined += segment\n",
    "        pause_duration = random.randint(min_pause, max_pause)\n",
    "        silence = AudioSegment.silent(duration=pause_duration)\n",
    "        combined += silence\n",
    "        cnt += 1\n",
    "        if cnt == 5:\n",
    "            break \n",
    "    combined.export(output_file, format=\"wav\")\n",
    "    print(f\"文件已保存至: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已保存至: ./data/origin_voice_data/debug.wav\n"
     ]
    }
   ],
   "source": [
    "get_tts_human_voice_data(\n",
    "    folder_path = tts_datapath\n",
    "    ,output_file = './data/origin_voice_data/debug.wav'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
